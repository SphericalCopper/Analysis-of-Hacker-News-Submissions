{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data Analysis of Hacker News submissions\n",
    "\n",
    "In this project, we'll analyze hacker news submissions of two main kinds:\n",
    "- Posts that start with \"Ask HN\"\n",
    "- Posts that start with \"Show HN\"\n",
    "\n",
    "\"Ask HN\" posts are posts where the author asks the board a forum, such as \"Is Tableau easier to use than Excel?\" \n",
    "\n",
    "\"Show HN\" posts are those where the author either makes a showcase of something they've done, or just wants to tell the board something of interest. \n",
    "\n",
    "Our goals are to find out the following:\n",
    "\n",
    "1) Do \"Ask HN\" or \"Show HN\" receive more comments on average?\n",
    "\n",
    "2) Does the time of the day a submission is posted have any bearing on the amount of comments a post receives? \n",
    "\n",
    "In this project we'll work with a data-set that originally consisted of 300,000 entries, which was reduced to 20,000 after flitering out submissions that didn't receive any comments, and then randomly selecting 20,000 posts from the remaining samples. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']]\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "\n",
    "opened_file = open('hacker_news.csv')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset comprises the following header columns: \n",
    "\n",
    "\n",
    "- title: title of the post (self explanatory)\n",
    "\n",
    "- url: the url of the item being linked to\n",
    "\n",
    "- num_points: the number of upvotes the post received\n",
    "\n",
    "- num_comments: the number of comments the post received\n",
    "\n",
    "- author: the name of the account that made the post\n",
    "\n",
    "- created_at: the date and time the post was made (the time zone is Eastern Time in the US)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']]\n",
      "\n",
      "\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']]\n"
     ]
    }
   ],
   "source": [
    "headers = hn[:1]\n",
    "\n",
    "hn = hn[1:]\n",
    "\n",
    "print(headers)\n",
    "print('\\n')\n",
    "print(hn[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744\n",
      "1162\n",
      "17194\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for each in hn:\n",
    "    title = each[1]\n",
    "    title = title.lower()\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(each)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(each)\n",
    "    else:\n",
    "        other_posts.append(each)\n",
    "        \n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've split up the \"ask hn\" and \"show hn\" posts, we'll next move on to tallying up the total number of comments both lists received, and then working out the average.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of posts \"ask hn\" posts receive:  14.038417431192661\n",
      "Average number of posts \"show hn\" posts receive:  10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "for each in ask_posts:\n",
    "    comments = float(each[4])\n",
    "    total_ask_comments += comments\n",
    "    \n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "\n",
    "print('Average number of posts \"ask hn\" posts receive: ', avg_ask_comments)\n",
    "\n",
    "total_show_comments = 0\n",
    "for each in show_posts:\n",
    "    comments = float(each[4])\n",
    "    total_show_comments += comments\n",
    "    \n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "\n",
    "print('Average number of posts \"show hn\" posts receive: ', avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, \"ask hn\" posts receive about 14.04 comments, whereas \"show hn\" posts receive about 10.32 comments. This is a fairly significant difference, with \"ask hn\" posts leading by almost 40% more comments.\n",
    "\n",
    "It's possible that this might be because \"ask hn\" posts inherently arouse more discussion, where people chime in with their opinions and then comment on the suggestions to the question raised.\n",
    "\n",
    "As such, the rest of the analysis will only center around \"ask hn\" posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding out comments received based on time of day posted\n",
    "\n",
    "We'll next aim to find out at which hour of the day a \"ask hn\" post has to be submitted for it to receive the most amount of comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'12': 687, '22': 479, '00': 447, '04': 337, '01': 683, '20': 1722, '09': 251, '15': 4477, '14': 1416, '23': 543, '11': 641, '10': 793, '06': 397, '17': 1146, '21': 1745, '08': 492, '13': 1253, '18': 1439, '03': 421, '19': 1188, '16': 1814, '05': 464, '02': 1381, '07': 267}\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for each in ask_posts:\n",
    "    created = each[6]\n",
    "    comments = int(each[4])\n",
    "    result_list.append([created, comments])\n",
    "    \n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for each in result_list:\n",
    "    comments = each[1]\n",
    "    date = each[0]\n",
    "    date = dt.datetime.strptime(date, \"%m/%d/%Y %H:%M\")\n",
    "    hour = date.strftime('%H')\n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = comments\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += comments\n",
    "        \n",
    "print(comments_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the comments by hour and amount of posts by hour, we can determine the average number of comments received per post, by hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12', 9.41095890410959], ['22', 6.746478873239437], ['00', 8.127272727272727], ['04', 7.170212765957447], ['01', 11.383333333333333], ['20', 21.525], ['09', 5.5777777777777775], ['15', 38.5948275862069], ['14', 13.233644859813085], ['23', 7.985294117647059], ['11', 11.051724137931034], ['10', 13.440677966101696], ['06', 9.022727272727273], ['17', 11.46], ['21', 16.009174311926607], ['08', 10.25], ['13', 14.741176470588234], ['18', 13.20183486238532], ['03', 7.796296296296297], ['19', 10.8], ['16', 16.796296296296298], ['05', 10.08695652173913], ['02', 23.810344827586206], ['07', 7.852941176470588]]\n"
     ]
    }
   ],
   "source": [
    "hours = []\n",
    "for each in comments_by_hour:\n",
    "    hours.append(each)\n",
    "\n",
    "\n",
    "avg_by_hour = []\n",
    "\n",
    "for each in hours:\n",
    "    comments = comments_by_hour[each]\n",
    "    counts = counts_by_hour[each]\n",
    "    \n",
    "    average = comments/counts\n",
    "    avg_by_hour.append([each, average])\n",
    "    \n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we obtained a list of lists that indicates the hour, as well as the average number of comments a \"ask hn\" post submitted at that hour received.\n",
    "\n",
    "Now, we'll sort this list out in a more readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.41095890410959, '12'], [6.746478873239437, '22'], [8.127272727272727, '00'], [7.170212765957447, '04'], [11.383333333333333, '01'], [21.525, '20'], [5.5777777777777775, '09'], [38.5948275862069, '15'], [13.233644859813085, '14'], [7.985294117647059, '23'], [11.051724137931034, '11'], [13.440677966101696, '10'], [9.022727272727273, '06'], [11.46, '17'], [16.009174311926607, '21'], [10.25, '08'], [14.741176470588234, '13'], [13.20183486238532, '18'], [7.796296296296297, '03'], [10.8, '19'], [16.796296296296298, '16'], [10.08695652173913, '05'], [23.810344827586206, '02'], [7.852941176470588, '07']]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for each in avg_by_hour: \n",
    "    swap_avg_by_hour.append([each[1], each[0]])\n",
    "    \n",
    "print(swap_avg_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[38.5948275862069, '15'],\n",
       " [23.810344827586206, '02'],\n",
       " [21.525, '20'],\n",
       " [16.796296296296298, '16'],\n",
       " [16.009174311926607, '21'],\n",
       " [14.741176470588234, '13'],\n",
       " [13.440677966101696, '10'],\n",
       " [13.233644859813085, '14'],\n",
       " [13.20183486238532, '18'],\n",
       " [11.46, '17'],\n",
       " [11.383333333333333, '01'],\n",
       " [11.051724137931034, '11'],\n",
       " [10.8, '19'],\n",
       " [10.25, '08'],\n",
       " [10.08695652173913, '05'],\n",
       " [9.41095890410959, '12'],\n",
       " [9.022727272727273, '06'],\n",
       " [8.127272727272727, '00'],\n",
       " [7.985294117647059, '23'],\n",
       " [7.852941176470588, '07'],\n",
       " [7.796296296296297, '03'],\n",
       " [7.170212765957447, '04'],\n",
       " [6.746478873239437, '22'],\n",
       " [5.5777777777777775, '09']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "\n",
    "sorted_swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments:\n",
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 5 Hours for Ask Posts Comments:\")\n",
    "\n",
    "for each in sorted_swap[:5]:\n",
    "    hour = each[1]\n",
    "    hour_datetime = dt.datetime.strptime(hour, \"%H\")\n",
    "    hour_string = hour_datetime.strftime(\"%H:%M\")\n",
    "    string = (\"{hour}: {comments:.2f} average comments per post\").format(hour = hour_string, comments = each[0])\n",
    "    print(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see the top 5 most ideal times to make a \"ask hn\" post that generates the most responses. \n",
    "\n",
    "These times are Eastern times in the US.  \n",
    "\n",
    "The highest time by a margin was 15:00 Eastern US time. Posts submitted at this time received 38.59 comments on average, which is almost twice the amount of comments received by the next best time, which is 2:00 Eastern US time.\n",
    "\n",
    "The popularity of posts submitted at 15:00 US time might have to do with the fact that at this time, it is evening in most of Europe, and around lunch hour in most of the US. \n",
    "\n",
    "# Conclusion\n",
    "\n",
    "The most ideal way to make a post that generates the most responses is by making an \"Ask HN\" flagged post around the 15:00-16:00 est time. This corresponds to 3a.m. - 4a.m. Singapore time, which is unfortunately a very poor choice of time for us here in South East Asia. \n",
    "\n",
    "The 2nd best time slot was 02:00 est, which corresponds to 2.00pm Singapore Time. This might be more suitable for most of us. \n",
    "\n",
    "It should be noted that because this data excluded the submissions which received no comments, the average number of comments per submission with the comment-less submissions included might be slightly different. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
